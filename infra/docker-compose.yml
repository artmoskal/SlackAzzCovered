# docker-compose.yaml (main file for full deployment)

include:
  - n8n-compose.yml

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  networks: ['app_network']
  environment:
    - OLLAMA_DEBUG=true
    - OLLAMA_HOST=0.0.0.0
    - GIN_DEBUG=true
    - GIN_MODE=debug
  logging:
    driver: "json-file"
    options:
      max-size: "200m"
      max-file: "3"
      mode: "non-blocking"
  deploy:
    resources:
      limits:
        memory: 8G
      reservations:
        memory: 4G
  ports:
    - 11434:11434
  volumes:
    - ollama_storage:/root/.ollama

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  networks: ['app_network']
  container_name: ollama-pull-llama
  volumes:
    - ollama_storage:/root/.ollama
  entrypoint: /bin/sh
  command:
    - "-c"
    - "sleep 3; OLLAMA_HOST=${OLLAMA_HOST_DOCKERIZED:-ollama:11434} ollama pull llama3.2"

services:
  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    image: cr.weaviate.io/semitechnologies/weaviate:latest
    ports:
      - 8080:8080
      - 50051:50051
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: on-failure
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: text2vec-transformers
      ENABLE_MODULES: 'text2vec-transformers,text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'
      CLUSTER_HOSTNAME: 'node1'
      AUTHENTICATION_APIKEY_ENABLED: 'true'
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: ${AUTHENTICATION_APIKEY_ALLOWED_KEYS}
      AUTHENTICATION_APIKEY_USERS: 'vectorDbUser'
      TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080
      # Add disk threshold configuration
      DISK_USE_READONLY_PERCENTAGE: "95" # Increase disk threshold to 95%
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s  # Give it more time to initialize
    networks:
      - app_network
    depends_on:
      t2v-transformers:
        condition: service_healthy

  t2v-init:
    image: semitechnologies/transformers-inference:sentence-transformers-paraphrase-multilingual-MiniLM-L12-v2
    networks:
      - app_network
    user: root
    volumes:
      - t2v-tools:/tools
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        mkdir -p /tools && cd /tools && \
        if [ ! -f bin/busybox ]; then
          # Only download and extract if busybox doesn't exist
          apt-get update && \
          apt-get download busybox && \
          dpkg -x busybox*.deb .
        fi && \
        # Just recreate the symlink
        rm -f wget && \
        ln -s bin/busybox wget && \
        echo "wget symlink created"

  # Main service
  t2v-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-paraphrase-multilingual-MiniLM-L12-v2
    environment:
      ENABLE_CUDA: '0'
      PATH: "/tools/usr/bin:${PATH}"
      LD_LIBRARY_PATH: "/tools/usr/lib/aarch64-linux-gnu:${LD_LIBRARY_PATH}"
    networks:
      - app_network
    user: root
    volumes:
      - t2v-tools:/tools
    healthcheck:
      test: ["CMD-SHELL", "/tools/wget -q -O - http://localhost:8080/.well-known/ready > /dev/null 2>&1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      t2v-init:
        condition: service_completed_successfully

  ollama-cpu:
    <<: *service-ollama


  ollama-pull-llama-cpu:
    <<: *init-ollama
    depends_on:
      - ollama-cpu

volumes:
  weaviate_data:
  t2v-tools:
  ollama_storage:

networks:
  app_network:
    driver: bridge
    attachable: true
    